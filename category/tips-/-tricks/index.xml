<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tips / Tricks | Sath Thavabalasingam</title>
    <link>https://sathesanthavabalasingam.github.io/category/tips-/-tricks/</link>
      <atom:link href="https://sathesanthavabalasingam.github.io/category/tips-/-tricks/index.xml" rel="self" type="application/rss+xml" />
    <description>Tips / Tricks</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© Sathesan Thavabalasingam 2021</copyright>
    <image>
      <url>https://sathesanthavabalasingam.github.io/images/icon_hu2ef9ecc646f8a390b864227564517363_24715_512x512_fill_lanczos_center_2.png</url>
      <title>Tips / Tricks</title>
      <link>https://sathesanthavabalasingam.github.io/category/tips-/-tricks/</link>
    </image>
    
    <item>
      <title>Using Kale &#43; Katib to save best fitted model</title>
      <link>https://sathesanthavabalasingam.github.io/post/kale-katib/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://sathesanthavabalasingam.github.io/post/kale-katib/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/kubeflow/kubeflow-kale-simplify-building-better-ml-pipelines-with-automatic-hyperparameter-tuning-5821747f4fcb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Kale&lt;/strong&gt;&lt;/a&gt; can be used to unify the workflow across components of ML projects, and presents a seamless process to create ML pipelines for HP tuning, starting from your Jupyter Notebook. One can use Kale to convert a Jupyter Notebook to a Kubeflow Pipeline without any modification to the original Python code. Within the Kale panel we can enable Hyperparameter tuning with [&lt;strong&gt;Kubeflow Katib&lt;/strong&gt;](&lt;a href=&#34;https://www.arrikto.com/tutorials/data-science/build-an-end-to-end-ml-workflow-from-notebook-to-hp-tuning-to-kubeflow-pipelines-with-kale/&#34;&gt;https://www.arrikto.com/tutorials/data-science/build-an-end-to-end-ml-workflow-from-notebook-to-hp-tuning-to-kubeflow-pipelines-with-kale/&lt;/a&gt;.&lt;/p&gt;


















&lt;figure id=&#34;figure-enable-kubeflow-katib-in-kale-panel-of-jupyter-notebook&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://codelabs.developers.google.com/codelabs/cloud-kubeflow-minikf-kale-katib/img/f4e34fff6a93aa60.png&#34; data-caption=&#34;Enable Kubeflow Katib in Kale panel of Jupyter notebook&#34;&gt;


  &lt;img src=&#34;https://codelabs.developers.google.com/codelabs/cloud-kubeflow-minikf-kale-katib/img/f4e34fff6a93aa60.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Enable Kubeflow Katib in Kale panel of Jupyter notebook
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Eventually, Kubeflow Katib will return information about the the best fitted model to the user.&lt;/p&gt;


















&lt;figure id=&#34;figure-best-model-result-returned-after-successful-tuning&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://codelabs.developers.google.com/codelabs/cloud-kubeflow-minikf-kale-katib/img/3b0ce47e548e5afb.png&#34; data-caption=&#34;Best model result returned after successful tuning&#34;&gt;


  &lt;img src=&#34;https://codelabs.developers.google.com/codelabs/cloud-kubeflow-minikf-kale-katib/img/3b0ce47e548e5afb.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Best model result returned after successful tuning
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;While metadata gets logged during pipeline execution, there were some limitations that I encountered when using Kubeflow Katib.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When using Katib, there is no apparent way to store fitted models/parameters in a location/registry&lt;/li&gt;
&lt;li&gt;E.g. It would be useful for us to know the name of the best trained model, parameters, and its model location in a storage bucket.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One workaround is to use &amp;lsquo;kubectl&amp;rsquo; commands to try and save fitted models and parameters in some location (e.g. storage bucket). Disclaimer: This workaround is cumbersome, and requires running Katib trials &lt;strong&gt;sequentially&lt;/strong&gt;, which is less than optimal. But hey &amp;ndash; it works for now (until I figure out a better solution)! Some code below to do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;storage_client = storage.Client()

model_filename = &#39;model.pkl&#39;
with open(model_filename, &#39;wb&#39;) as f:
    pickle.dump(dct, f)

# save model params
params_filename = &#39;params.pkl&#39;
params={&#39;params&#39; : dct.get_params(),&#39;feature_names&#39; : train.columns.to_list()}
with open(params_filename, &#39;wb&#39;) as f:
    pickle.dump(params, f)

resul = os.popen(&#39;kubectl get experiment -n kubeflow-user&#39;).readlines()
res = [resul[x].split() for x in range(len(resul))]
res=pd.DataFrame(res[1:], columns=res[0])
experiment_name = res[res.STATUS==&#39;Running&#39;][&#39;NAME&#39;].values[0]    

bucket = storage_client.get_bucket(&#39;bm-kubeflow-lab-kubeflowpipelines-default&#39;)
resul = os.popen(&#39;kubectl get trial -n kubeflow-user&#39;).readlines()
res = [resul[x].split() for x in range(len(resul))]
res=pd.DataFrame(res[1:], columns=res[0])
trial_name = res[res.TYPE==&#39;Running&#39;][&#39;NAME&#39;].values[0]
model_load = bucket.blob(&#39;test_upload/{}/{}/{}&#39;.format(experiment_name, trial_name,model_filename))
model_load.upload_from_filename(model_filename)
params_load = bucket.blob(&#39;test_upload/{}/{}/{}&#39;.format(experiment_name, trial_name,params_filename))
params_load.upload_from_filename(params_filename)

#store experiment name in bigquery table to track experiment names, and dates in which jobs were run.
exp_table = pd.DataFrame(data=[experiment_name], columns=[&#39;experiment_name&#39;])
bq_client = bq.Client()
dataset_ref = bq_client.dataset(&#39;project_dataset&#39;)
table_ref = dataset_ref.table(&#39;katib_experiments&#39;)
job_config = bq.LoadJobConfig()
job_config.write_disposition = bq.WriteDisposition.WRITE_TRUNCATE
job = bq_client.load_table_from_dataframe(dataframe=exp_table, destination=table_ref, job_config=job_config)
job.result()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After hyperparameter tuning has run sucessfully with Kubeflow Katib, we can access the name of the best trial, go into its associated directory where the fitted model is stored and move this to a separate directory for later access (e.g. for serving scripts)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# check best model and update a seperate &amp;quot;deploy&amp;quot; folder with this model. Might need to put this source code as a final step executed after full pipeline is run.
resul=os.popen(&#39;kubectl -n kubeflow-user get experiment {} -o yaml&#39;.format(experiment_name)).readlines()
res =[resul[x].split() for x in range(len(resul))]
res=pd.DataFrame(res)
best_trial = res[res[0]==&#39;bestTrialName:&#39;][1].values[0]
if best_trial != &#39;&amp;quot;&amp;quot;&#39;:
    files = bucket.list_blobs(prefix=&#39;test_upload/{}/{}/&#39;.format(experiment_name ,best_trial))
    fileList = [file for file in files]
    for file in fileList:
        file_name = file.name.split(&#39;/&#39;)[-1]
       bucket.rename_blob(file, &#39;test_upload/best_models/deploy/{}&#39;.format(file_name))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
