[{"authors":null,"categories":null,"content":"I am currently a Data Scientist at Tangerine Bank, an online and mobile banking company. My interests include developing elegant solutions to solve problems using data and analytics. In my role I am involved in developing predictive models to drive acquisition and pricing optimization at Tangerine.\nPrior to transitioning to Data Science, my Ph.D research revolved around exploring human memory and perception.\n","date":1611360000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611360000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently a Data Scientist at Tangerine Bank, an online and mobile banking company. My interests include developing elegant solutions to solve problems using data and analytics. In my role I am involved in developing predictive models to drive acquisition and pricing optimization at Tangerine.","tags":null,"title":"Sathesan Thavabalasingam","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://sathesanthavabalasingam.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1614643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614643200,"objectID":"414aa6c09175daee08e88dcc39f54407","permalink":"https://sathesanthavabalasingam.github.io/project/text-recognizer/","publishdate":"2021-03-02T00:00:00Z","relpermalink":"/project/text-recognizer/","section":"project","summary":"Implementation of FSDL line text recognizer web app.","tags":["Deep Learning"],"title":"Line Text Recognizer (Full-Stack Deep Learning)","type":"project"},{"authors":["Sathesan Thavabalasingam"],"categories":["Medium Post"],"content":"Overview In this Medium post I discuss the Tweedie distribution and use of the tweedie loss function and how to implement this in Python. When building predictive models, it is not uncommon to observe data with right-skewed distribution and long tail. For example, in a large e-commerce company like Amazon, most users entering the site will likely not make a purchase, and if they do, the value ranges between cents and thousands of dollars. As a consequence we may have oddly shaped \u0026ldquo;zero-inflated\u0026rdquo; distributions with a point mass at zero. Under this circumstance, prediction models may not be well trained if loss functions for other distributions (e.g., RMSE for Gaussian distributions) are used.\n","date":1611360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611360000,"objectID":"924c0277fdf5f50888d18df0b8524ef6","permalink":"https://sathesanthavabalasingam.github.io/post/tweedie-loss/","publishdate":"2021-01-23T00:00:00Z","relpermalink":"/post/tweedie-loss/","section":"post","summary":"In this post on medium, I describe the Tweedie loss function and how it can be used to model zero-inflated data.","tags":["Machine Learning","Data Science","Regression","Loss Function"],"title":"Tweedie Loss Function","type":"post"},{"authors":["Sathesan Thavabalasingam"],"categories":["Tips / Tricks"],"content":"Overview Kale can be used to unify the workflow across components of ML projects, and presents a seamless process to create ML pipelines for HP tuning, starting from your Jupyter Notebook. One can use Kale to convert a Jupyter Notebook to a Kubeflow Pipeline without any modification to the original Python code. Within the Kale panel we can enable Hyperparameter tuning with [Kubeflow Katib](https://www.arrikto.com/tutorials/data-science/build-an-end-to-end-ml-workflow-from-notebook-to-hp-tuning-to-kubeflow-pipelines-with-kale/.\n  Enable Kubeflow Katib in Kale panel of Jupyter notebook   Eventually, Kubeflow Katib will return information about the the best fitted model to the user.\n  Best model result returned after successful tuning   While metadata gets logged during pipeline execution, there were some limitations that I encountered when using Kubeflow Katib.\n When using Katib, there is no apparent way to store fitted models/parameters in a location/registry E.g. It would be useful for us to know the name of the best trained model, parameters, and its model location in a storage bucket.  One workaround is to use \u0026lsquo;kubectl\u0026rsquo; commands to try and save fitted models and parameters in some location (e.g. storage bucket). Disclaimer: This workaround is cumbersome, and requires running Katib trials sequentially, which is less than optimal. But hey \u0026ndash; it works for now (until I figure out a better solution)! Some code below to do this:\nstorage_client = storage.Client() model_filename = 'model.pkl' with open(model_filename, 'wb') as f: pickle.dump(dct, f) # save model params params_filename = 'params.pkl' params={'params' : dct.get_params(),'feature_names' : train.columns.to_list()} with open(params_filename, 'wb') as f: pickle.dump(params, f) resul = os.popen('kubectl get experiment -n kubeflow-user').readlines() res = [resul[x].split() for x in range(len(resul))] res=pd.DataFrame(res[1:], columns=res[0]) experiment_name = res[res.STATUS=='Running']['NAME'].values[0] bucket = storage_client.get_bucket('bm-kubeflow-lab-kubeflowpipelines-default') resul = os.popen('kubectl get trial -n kubeflow-user').readlines() res = [resul[x].split() for x in range(len(resul))] res=pd.DataFrame(res[1:], columns=res[0]) trial_name = res[res.TYPE=='Running']['NAME'].values[0] model_load = bucket.blob('test_upload/{}/{}/{}'.format(experiment_name, trial_name,model_filename)) model_load.upload_from_filename(model_filename) params_load = bucket.blob('test_upload/{}/{}/{}'.format(experiment_name, trial_name,params_filename)) params_load.upload_from_filename(params_filename) #store experiment name in bigquery table to track experiment names, and dates in which jobs were run. exp_table = pd.DataFrame(data=[experiment_name], columns=['experiment_name']) bq_client = bq.Client() dataset_ref = bq_client.dataset('project_dataset') table_ref = dataset_ref.table('katib_experiments') job_config = bq.LoadJobConfig() job_config.write_disposition = bq.WriteDisposition.WRITE_TRUNCATE job = bq_client.load_table_from_dataframe(dataframe=exp_table, destination=table_ref, job_config=job_config) job.result()  After hyperparameter tuning has run sucessfully with Kubeflow Katib, we can access the name of the best trial, go into its associated directory where the fitted model is stored and move this to a separate directory for later access (e.g. for serving scripts)\n# check best model and update a seperate \u0026quot;deploy\u0026quot; folder with this model. Might need to put this source code as a final step executed after full pipeline is run. resul=os.popen('kubectl -n kubeflow-user get experiment {} -o yaml'.format(experiment_name)).readlines() res =[resul[x].split() for x in range(len(resul))] res=pd.DataFrame(res) best_trial = res[res[0]=='bestTrialName:'][1].values[0] if best_trial != '\u0026quot;\u0026quot;': files = bucket.list_blobs(prefix='test_upload/{}/{}/'.format(experiment_name ,best_trial)) fileList = [file for file in files] for file in fileList: file_name = file.name.split('/')[-1] bucket.rename_blob(file, 'test_upload/best_models/deploy/{}'.format(file_name))  ","date":1611360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611360000,"objectID":"3d44257676f0443540802ba249ade0e2","permalink":"https://sathesanthavabalasingam.github.io/post/kale-katib/","publishdate":"2021-01-23T00:00:00Z","relpermalink":"/post/kale-katib/","section":"post","summary":"Some code to help with saving each fitted model and parameters for hyperparameter tuning with Kubeflow Katib.","tags":["Machine Learning","Data Science","MLOps","Kubeflow"],"title":"Using Kale + Kubeflow Katib to Save Best Fitted Model","type":"post"},{"authors":["Sonja Chu","Matthew Margerison","Sathesan Thavabalasingam","Edward B. O'Neil","Yuan-Fang Zhao","Rutsuko Ito","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1610236800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610236800,"objectID":"9865b87526c434af04f1db165489aa7e","permalink":"https://sathesanthavabalasingam.github.io/publication/chu-cer-2021/","publishdate":"2021-01-10T00:00:00Z","relpermalink":"/publication/chu-cer-2021/","section":"publication","summary":"false","tags":["decision-making","functional MRI","medial temporal lobe","memory","conflict"],"title":"Perirhinal cortex is involved in the resolution of learned approach–avoidance conflict associated with discrete objects","type":"publication"},{"authors":["Sonja Chu","Sathesan Thavabalasingam","Laurie Hamel","Supreet Aashat","Rutsuko Ito","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1606953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606953600,"objectID":"d5bed79ffc9f161969d3903ff23a3eec","permalink":"https://sathesanthavabalasingam.github.io/publication/chu-mem-2020/","publishdate":"2020-12-03T00:00:00Z","relpermalink":"/publication/chu-mem-2020/","section":"publication","summary":"false","tags":["Approach-avoidance conflict","memory","encoding","transitive inference"],"title":"Exploring the interaction between approach-avoidance conflict and memory processing","type":"publication"},{"authors":["Andy C H Lee","Sathesan Thavabalasingam","Denada Alushaj","Bilgehan Çavdaroğlu","Rutsuko Ito"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1580688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580688000,"objectID":"d4fb1c8b620b56ab42da052844ca6035","permalink":"https://sathesanthavabalasingam.github.io/publication/lee-neuropsy-2020/","publishdate":"2020-02-03T00:00:00Z","relpermalink":"/publication/lee-neuropsy-2020/","section":"publication","summary":"Cross-species evidence supports a role for the hippocampus in duration memory. Discrepancies in findings cloud the conditions governing hippocampal involvement. We suggest the importance of considering the hippocampus as a sequence processor. The hippocampus supports duration memory in the context of event sequences. Overlapping hippocampal mechanisms may support memory for duration and order.","tags":["Hippocampus","Episodic memory","Time","Sequences","Duration","Order"],"title":"The hippocampus contributes to temporal duration memory in the context of event sequences: A cross-species perspective","type":"publication"},{"authors":["Daniela J Palombo","Allison G. Reid","Sathesan Thavabalasingam","Renée Hunsberger","Andy C H Lee","Mieke Verfaellie"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1580342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580342400,"objectID":"0dced0d0089ed83bca06e7af3c3f2c5c","permalink":"https://sathesanthavabalasingam.github.io/publication/djp-jcogn-2020/","publishdate":"2020-01-30T00:00:00Z","relpermalink":"/publication/djp-jcogn-2020/","section":"publication","summary":"false","tags":["time","duration","medial temporal lobe","memory","amnesia","patient"],"title":"The human medial temporal lobe is necessary for remembering durations within a sequence of events but not durations of individual events","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1558915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558915200,"objectID":"bef88a61ed10f3ca4cf9bd8574285ab3","permalink":"https://sathesanthavabalasingam.github.io/project/wildfire-app/","publishdate":"2019-05-27T00:00:00Z","relpermalink":"/project/wildfire-app/","section":"project","summary":"A simple web application built with Flask, Python and Google App Engine to assist project procurement by connecting vendors with the right buyers.","tags":["Other"],"title":"WildFire","type":"project"},{"authors":["Sathesan Thavabalasingam","Edward B. O'Neil","Jonathan Tay","Adrian Nestor","Andy C H Lee"],"categories":null,"content":"Supplementary notes can be added here, including code, math, and images.\n","date":1553558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553558400,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://sathesanthavabalasingam.github.io/publication/example/","publishdate":"2019-03-26T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"We demonstrate that multivariate patterns of activity in the human hippocampus during the recognition and cued mental replay of long-term sequence memories contain temporal structure information in the order of seconds. By using an experimental paradigm that required participants to remember the durations of empty intervals between visually presented scene images, our study provides evidence that the human hippocampus can represent elapsed time within a sequence of events in conjunction with other forms of information, such as event content. Our findings complement rodent studies that have shown that hippocampal neurons fire at specific times during the empty delay between two events and suggest a common hippocampal neural mechanism for representing temporal information in the service of episodic memory.","tags":["hippocampus","CA1","episodic memory","time","functional magnetic resonance imaging"],"title":"Evidence for the incorporation of temporal duration information in human hippocampal long-term memory sequence representations","type":"publication"},{"authors":["Sathesan Thavabalasingam","Edward B. O'Neil","Jonathan Tay","Adrian Nestor","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1553558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553558400,"objectID":"a47da2185a0da2e1c5866c3381d89160","permalink":"https://sathesanthavabalasingam.github.io/publication/st-pnas-2019/","publishdate":"2019-03-26T00:00:00Z","relpermalink":"/publication/st-pnas-2019/","section":"publication","summary":"We demonstrate that multivariate patterns of activity in the human hippocampus during the recognition and cued mental replay of long-term sequence memories contain temporal structure information in the order of seconds. By using an experimental paradigm that required participants to remember the durations of empty intervals between visually presented scene images, our study provides evidence that the human hippocampus can represent elapsed time within a sequence of events in conjunction with other forms of information, such as event content. Our findings complement rodent studies that have shown that hippocampal neurons fire at specific times during the empty delay between two events and suggest a common hippocampal neural mechanism for representing temporal information in the service of episodic memory.","tags":["hippocampus","CA1","episodic memory","time","functional magnetic resonance imaging"],"title":"Evidence for the incorporation of temporal duration information in human hippocampal long-term memory sequence representations","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1551225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551225600,"objectID":"8221ef2b9df2b5be6c31171268fd5ae0","permalink":"https://sathesanthavabalasingam.github.io/project/skipthoughts/","publishdate":"2019-02-27T00:00:00Z","relpermalink":"/project/skipthoughts/","section":"project","summary":"Evaluation of skip-thoughts model outlined in Kiros paper (https://arxiv.org/pdf/1506.06726.pdf)","tags":["Deep Learning"],"title":"Evaluation of skipthoughts model","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://sathesanthavabalasingam.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Sathesan Thavabalasingam","Edward B. O'Neil","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"62d4d95dbd5195d0a69e3394afdfb486","permalink":"https://sathesanthavabalasingam.github.io/publication/st-neuroim-2018/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/publication/st-neuroim-2018/","section":"publication","summary":"Hippocampal activity patterns are sensitive to temporal order and duration. Duration sensitivity is not dependant on explicit temporal processing. Findings support a temporal representation of event sequences in the hippocampus.","tags":["Hippocampus","Memory","Time","Event sequences","Functional magnetic resonance imaging"],"title":"Multivoxel pattern similarity suggests the integration of temporal duration in hippocampal event sequence representations","type":"publication"},{"authors":["Danielle Douglas","Sathesan Thavabalasingam","Zahraa Chorghay","Edward B. O'Neil","Morgan D Barense","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1508630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508630400,"objectID":"4267efade7a121c3b690d72206e70ebc","permalink":"https://sathesanthavabalasingam.github.io/publication/dd-hippo-2017/","publishdate":"2017-10-22T00:00:00Z","relpermalink":"/publication/dd-hippo-2017/","section":"publication","summary":"Surprisingly little is known about how the brain combines spatial elements to form a coherent percept. Regions that may underlie this process include the hippocampus (HC) and parahippocampal place area (PPA), regions central to spatial perception but whose role in spatial coherency has not been explored. Participants were scanned with functional MRI while they judged whether Escher‐like scenes were possible or impossible. Univariate analyses revealed differential HC and PPA involvement, with greater HC activity during spatial incoherency detection and more PPA activity during spatial coherency detection. Recognition and eye‐tracking data ruled out long‐ or short‐term memory confounds. Multivariate statistics demonstrated spatial coherency‐dependent functional connectivity for the HC, but not PPA, with greater HC connectivity to various brain regions including lateral occipital complex during spatial incoherency detection. We suggest the PPA is preferentially involved during the perception of spatially coherent scenes, whereas the HC binds distinct features to create coherent representations.","tags":["Hippocampus","Memory","Time","Event sequences","Functional magnetic resonance imaging"],"title":"Perception of impossible scenes reveals differential hippocampal and parahippocampal place area contributions to spatial coherency","type":"publication"},{"authors":["Sathesan Thavabalasingam","Edward B. O'Neil","Zheng Zeng","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"804bb0f2b7d0dbcf27272dd6c849d5c1","permalink":"https://sathesanthavabalasingam.github.io/publication/st-frontpsy-2016/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/st-frontpsy-2016/","section":"publication","summary":"In order to function optimally within our environment, we continuously extract temporal patterns from our experiences and formulate expectations that facilitate adaptive behavior. Given that our memories are embedded within spatiotemporal contexts, an intriguing possibility is that mnemonic processes are sensitive to the temporal structure of events. To test this hypothesis, in a series of behavioral experiments we manipulated the regularity of interval durations at encoding to create temporally structured and unstructured frameworks. Our findings revealed enhanced recognition memory (d′) for stimuli that were explicitly encoded within a temporally structured vs. unstructured framework. Encoding information within a temporally structured framework was also associated with a reduction in the negative effects of proactive interference and was linked to greater recollective recognition memory. Furthermore, rhythmic temporal structure was found to enhance recognition memory for incidentally encoded information. Collectively, these results support the possibility that we possess a greater capacity to learn and subsequently remember temporally structured information.","tags":["timing","rhythm","duration","memory","encoding","d-prime"],"title":"Recognition Memory is Improved by a Structured Temporal Framework During Encoding","type":"publication"},{"authors":["Edward B. O'Neil","Rachel Newsome","Iris H N Li","Sathesan Thavabalasingam","Rutsuko Ito","Andy C H Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1447200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447200000,"objectID":"47e3e1eeba9da1d1fdbda9b4ee6773a7","permalink":"https://sathesanthavabalasingam.github.io/publication/eo-jneuro-2015/","publishdate":"2015-11-11T00:00:00Z","relpermalink":"/publication/eo-jneuro-2015/","section":"publication","summary":"Approach–avoidance conflict has been linked to anxiety and occurs when a stimulus or situation is associated with reward and punishment. Although rodent work has implicated the hippocampus in approach–avoidance conflict processing, there is limited data on whether this role applies to learned, as opposed to innate, incentive values, and whether the human hippocampus plays a similar role. Using functional neuroimaging with a novel decision-making task that controlled for perceptual and mnemonic processing, we found that the human hippocampus was significantly active when approach–avoidance conflict was present for stimuli with learned incentive values. These findings demonstrate a role for the human hippocampus in approach–avoidance decision making that cannot be explained easily by hippocampal-dependent long-term memory or spatial cognition.","tags":["approach–avoidance conflict","decision-making","functional magnetic resonance imaging","hippocampus","memory"],"title":"Examining the role of the human hippocampus in approach–avoidance decision making using a novel conflict paradigm and multivariate functional magnetic resonance imaging","type":"publication"}]